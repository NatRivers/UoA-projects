{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6a6a734-7d3e-48c6-bbaf-67f6e270c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cac4144-932e-41b8-abdf-449397702288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_val(db_df, prev_lst):\n",
    "    db_df['sup'] = 0 #set value to 0 for initial value at every iter\n",
    "    count_freq = []\n",
    "\n",
    "    #Set the init value of prev candidate to 0\n",
    "    for item in prev_lst:\n",
    "        count_freq.append((item, 0))\n",
    "\n",
    "    df_candidate = pd.DataFrame(count_freq, columns=['itemset', 'sup'])\n",
    "\n",
    "    for i in range(len(db_df)):\n",
    "        for j in range(len(count_freq)):\n",
    "            #check if itemset is subset of Database\n",
    "            if (df_candidate['itemset'][j]).issubset(set(db_df['items'][i])): \n",
    "                df_candidate.loc[j, 'sup'] += 1\n",
    "                \n",
    "    # for s in range (len(df_candidate)):\n",
    "    #     df_candidate['sup'].iloc[s] = float(df_candidate['sup'].iloc[s]) / len(db_df)\n",
    "    return df_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd2f270-3b27-44ef-ae3e-b675f20f5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_freq_element(minsup,prev_candidate):\n",
    "    filtering = prev_candidate['sup'] >= minsup\n",
    "    freq = prev_candidate[filtering]\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0c7ead7-2f59-4c5e-ac3a-19e24d7a322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_freq(itemset):\n",
    "    join_lst = []\n",
    "    for i in range(len(itemset['itemset'])):\n",
    "        for j in range((i+1), len(itemset['itemset'])):\n",
    "            itemset_i = itemset['itemset'].iloc[i]\n",
    "            itemset_j = itemset['itemset'].iloc[j]\n",
    "            if type(itemset_i) == str and type(itemset_j) == str:\n",
    "                itemset_i = {itemset_i}\n",
    "                itemset_j = {itemset_j}\n",
    "\n",
    "            union_candidate = itemset_i.union(itemset_j)\n",
    "\n",
    "            if union_candidate not in join_lst:\n",
    "                join_lst.append(union_candidate)\n",
    "    return join_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e96ef479-cf41-4132-bbbf-bcd68745e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_val(db_df,rules,minconf): #Probability(A & B) / Support(A)\n",
    "    confdict = {}\n",
    "    for i in range (len(rules)):\n",
    "        for k in rules[i].keys():\n",
    "            key_lst = k.split(\", \")\n",
    "            key_sup = support_val(db_df, [set(key_lst)]) #Support(A)\n",
    "            AandB = sorted(key_lst + rules[i][k]) \n",
    "            prob_val = support_val(db_df, [set(AandB)])#prob(A&B)\n",
    "            if int(key_sup['sup']) == 0: #division by 0 prevention\n",
    "                conf=0\n",
    "            else:\n",
    "                conf = int(prob_val['sup']) / int(key_sup['sup'])\n",
    "            # print(key_sup)\n",
    "            # print(prob_val)\n",
    "            # print(conf)\n",
    "            if conf >= minconf: #get rules >= minconf \n",
    "                confdict[k + \"->\" + \",\".join(rules[i][k])] = conf\n",
    "    return confdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "037524c4-f80f-4b7c-9075-ff2f2b665551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_val(db_df, confdict): #confidence(A->B) / support(B)\n",
    "    liftdict = {}\n",
    "    for k in confdict.keys():\n",
    "        confvalue = confdict[k]\n",
    "        b = k[k.find(\">\")+1:].split(\",\") #> in ->\n",
    "        supportB = support_val(db_df, [set(b)])\n",
    "        liftvalue = confvalue / int(supportB['sup'])\n",
    "        liftdict[k]=liftvalue\n",
    "    return liftdict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881fb6bb-9556-40d2-ae2e-b68511b5a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rules(candidate):\n",
    "    rules = []\n",
    "    dict_rules = {}\n",
    "    for i in range(len(candidate['itemset'])):\n",
    "        dict_rules = {}\n",
    "        items = sorted(list(candidate['itemset'].iloc[i]))\n",
    "        temp_i = items[:]\n",
    "        for j in range(len(items)):\n",
    "            k = temp_i[j]\n",
    "            del temp_i[j]\n",
    "            if type(temp_i) is not list:\n",
    "                temp_i = [temp_i]\n",
    "            dict_rules[k] = temp_i\n",
    "            dict_rules[\", \".join(temp_i)] = [k]\n",
    "            temp_i = items[:]\n",
    "        rules.append(dict_rules)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aa9d96d-a13f-4c17-9b97-54887c40a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_conf_sup(db_df,liftdata, confdata, minsup): #for Task2 to generate values\n",
    "    data = []\n",
    "    for k in liftdata.keys():\n",
    "        setdata = k[:k.find(\"-\")].split(\", \") + k[k.find(\">\")+1:].split(\",\")\n",
    "        sup = support_val(db_df,[set(setdata)])\n",
    "        data.append((k,liftdata[k], confdata[k],float(sup['sup'])))\n",
    "    data = sorted(data)\n",
    "    all_data = pd.DataFrame(data, columns=['rule', 'lift', 'conf', 'sup'])\n",
    "    all_data = filter_freq_element(minsup,all_data)\n",
    "    all_data = all_data.reset_index(drop=True)\n",
    "    print(all_data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81892739-4edb-4ca6-949d-5cf74bd7d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(minsup,minconf,minlift,csv):\n",
    "    dataset = pd.read_csv(csv, on_bad_lines='skip', header=None)\n",
    "    item_dict = {}\n",
    "    for r in range (len(dataset)):\n",
    "        for item in dataset.iloc[r]:\n",
    "            if type(item)!=str or \"total\" in item: #if value is NaN, end of transaction, exit loop\n",
    "                break\n",
    "            if r not in item_dict:\n",
    "                item_dict[r]=[item]\n",
    "            else:\n",
    "                item_dict[r].append(item)\n",
    "        item_dict[r].sort()\n",
    "\n",
    "    item_lst = []\n",
    "    for k in item_dict.keys():\n",
    "        item_lst.append(item_dict[k])\n",
    "\n",
    "    dict_data = {'items': item_lst}\n",
    "    df = pd.DataFrame.from_dict(dict_data)\n",
    "\n",
    "    content = []\n",
    "    for i in item_lst:\n",
    "        for q in i:\n",
    "            if(q not in content):\n",
    "                content.append(q)\n",
    "    content.sort()\n",
    "    minsup *= len(dataset)\n",
    "    \n",
    "    #first iter sup (count individual items frequency)\n",
    "    counter = 0\n",
    "    count_content = []\n",
    "    for i in content:\n",
    "        for d in item_lst:\n",
    "            if i in d:\n",
    "                counter += 1\n",
    "        count_content.append((i, counter))\n",
    "        counter = 0 #reset counter\n",
    "    c1_df = pd.DataFrame(count_content, columns=[\"itemset\", \"sup\"])\n",
    "    freqset = filter_freq_element(minsup,c1_df)\n",
    "    \n",
    "    #repeat apriori algorithm until length of dataframe is either 0 or 1\n",
    "    #0 means that no data is in dataframe, stop iteration\n",
    "    #1 means that no more combination of set, stop iteration (data support val can be < or >= minsup)\n",
    "    tempset = 0 #to check if prevset=currentset, if same then set is final, no need to iterate further\n",
    "    while len(freqset)!=0 and len(freqset)!=1 and tempset!=len(freqset):\n",
    "        join = join_freq(freqset)\n",
    "        count_content = []\n",
    "        for item in join:\n",
    "            count_content.append((item, 0))\n",
    "        candidate = pd.DataFrame(count_content, columns=['itemset', 'sup'])\n",
    "        candidate = support_val(df,join)\n",
    "        freqset = filter_freq_element(minsup,candidate)\n",
    "        reset_index = freqset.reset_index(drop=True)\n",
    "        tempset=len(candidate) #if no changes then candinate=reset_index since no data is pruned\n",
    "        rules = association_rules(reset_index)\n",
    "        #print(rules)\n",
    "        conf = confidence_val(df,rules,minconf)\n",
    "        #print(conf)\n",
    "        lift = lift_val(df, conf)\n",
    "        alldata = lift_conf_sup(df,lift,conf,minsup)\n",
    "        print()\n",
    "        \n",
    "    if len(freqset) == 1: #if final set is only 1, check support value if it's >=minsup\n",
    "        check_supVal = reset_index['sup'].iloc[0] >= minsup\n",
    "        if check_supVal: #get rules if >=minsup and >=minconf\n",
    "            rules = association_rules(reset_index)\n",
    "            conf = confidence_val(df,rules,minconf)\n",
    "            lift = lift_val(df, conf)\n",
    "            alldata = lift_conf_sup(df,lift,conf,minsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e1fea-a6da-4463-b71e-824636dd6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(0.2,0.6,0,'supermarket.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660524c1-cbce-4054-b866-1db6766474e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
